<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://artpiazcode.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://artpiazcode.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-01-06T15:39:12+00:00</updated><id>https://artpiazcode.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">ModernBERT</title><link href="https://artpiazcode.github.io/blog/2024/ModernBERT/" rel="alternate" type="text/html" title="ModernBERT"/><published>2024-12-25T00:00:00+00:00</published><updated>2024-12-25T00:00:00+00:00</updated><id>https://artpiazcode.github.io/blog/2024/ModernBERT</id><content type="html" xml:base="https://artpiazcode.github.io/blog/2024/ModernBERT/"><![CDATA[<h3 id="key-takeaways">Key takeaways</h3> <ul> <li>Latest encoder-only transformer model. Biggest leap since RoBERTa.</li> <li>Developed by Answer.AI</li> <li>Modernized transformer architecture</li> <li>Attention to efficiency</li> <li>Increased data scales and sources</li> </ul> <h3 id="training-details">Training details</h3> <ul> <li>2 trillion tokens</li> <li>Native sequence length 8192 tokens</li> </ul> <h3 id="architectural-improvements">Architectural improvements</h3> <p><img src="positional_encoding.png" alt="alt text"/></p> <h4 id="rotary-positional-embeddings">Rotary positional embeddings</h4> <h4 id="bias-terms">Bias terms</h4> <p>What are bias terms?</p> <h3 id="references">References</h3> <p><a href="https://huggingface.co/docs/transformers/main/en/model_doc/modernbert">Huggingface model</a></p>]]></content><author><name></name></author><category term="paper-readings"/><category term="bert"/><summary type="html"><![CDATA[ModernBERT]]></summary></entry><entry><title type="html">Positional Embeddings</title><link href="https://artpiazcode.github.io/blog/2024/Positional-Embeddings/" rel="alternate" type="text/html" title="Positional Embeddings"/><published>2024-07-07T00:00:00+00:00</published><updated>2024-07-07T00:00:00+00:00</updated><id>https://artpiazcode.github.io/blog/2024/Positional%20Embeddings</id><content type="html" xml:base="https://artpiazcode.github.io/blog/2024/Positional-Embeddings/"><![CDATA[<p>One of the key component for transformers are <b>positional embeddings</b>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/transformer-480.webp 480w,/assets/img/transformer-800.webp 800w,/assets/img/transformer-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/transformer.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Transformer by design does not take into account the order of the tokens. Attention mechanism treats a sequence as a bag of tokens. The processing of the embedding vectors in the transformer attention block to transform into query, key and value vector occurs in parallel. Therefore, the information about the order is not captured. For this reason, positional embeddings are important to take account for the order of tokens; ex. consider : <strong>The man attacked the tiger</strong> vs <strong>The tiger attacked the man</strong>.</p> <p>Position embeddings are a unique embedding generated for each position in the sequence. These are dense vectors representing the position of each token in the sequence. The token embedding (dense vector representation of each token in input sequence capturing the semantic meaning of the token) and the positional embeddings (offset vector) are combined to result in a new vector that contains both semantic and position information.</p> <p>The positional embeddings value cannot be too large. If the positional embeddings (which are offset vectors) are too lartge, then the combined vector will get offset by a very large distance destroying the overall concept of the embedding space where word vector closely related are close to one another. Therefore, the mathematical function to model the positional embeddings should be bounded like sine / cosine (value between -1 and +1).</p> <p><strong>Attention is all you need</strong> paper defined positional embedding as a combination of sine and cosine functions of the position in input sequence and dimension of the output embedding space.</p> <p>RoPE was first introduced in 2022 RoFormer paper https://arxiv.org/pdf/2104.09864.</p> <p>The goal for position encoding is to enable supervision for dependency modeling between elements at different positions of the sequence.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/RoPE-480.webp 480w,/assets/img/RoPE-800.webp 800w,/assets/img/RoPE-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/RoPE.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>RoPE encodes the absolute position with a rotation matrix and meanwhile incorporates the explicit relative position dependency in self attention formulation.</p> <ul> <li>Flexibility of sequence length</li> <li>Decaying inter-token dependency with increasing relative distances</li> <li>Capability if equipping the linear self-attention with relative position encoding.</li> </ul>]]></content><author><name></name></author><category term="concepts"/><category term="transformer"/><summary type="html"><![CDATA[One of the key component for transformers are positional embeddings.]]></summary></entry><entry><title type="html">BERT</title><link href="https://artpiazcode.github.io/blog/2023/BERT/" rel="alternate" type="text/html" title="BERT"/><published>2023-06-20T00:00:00+00:00</published><updated>2023-06-20T00:00:00+00:00</updated><id>https://artpiazcode.github.io/blog/2023/BERT</id><content type="html" xml:base="https://artpiazcode.github.io/blog/2023/BERT/"><![CDATA[<ul> <li>2018</li> <li>Most cited paper</li> <li>Largest Model : 340M parameters</li> <li>Bidirectional Encoder Representations from Transformers</li> <li> <p>Improves upon standard transformers </p> <ul> <li> <p>Removes the unidirectionality constraint by using a masked language model (MLM) pretraining objective. </p> </li> <li> <p>The masked language model randomly masks some of the tokens from the input, and the objective is to predict the original vocabulary id of the masked word based only on its context.</p> </li> <li> <p>Unlike Left-to-right language model pre-training, the MLM objective enables the representation to fuse the left and the right context, which allows us to pretrain a deep bidirectional Transformer. </p> </li> <li> <p>In addition to MLM, BERT also uses a next sentence prediction task that jointly pre-trains text-pair representations. * There are two steps in BERT: pre-training and fine-tuning. - <strong>During pre-training, the model is trained on unlabeled data over different pre-training tasks.</strong> </p> </li> </ul> </li> <li> <p>For fine-tuning, the BERT model is first initialized with the pre-trained parameters, and all of the parameters are fine-tuned using labeled data from the downstream tasks. </p> </li> <li>Each downstream task has separate fine-tuned models, even though they are initialized with the same pre-trained parameters.<img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeN9jIi6JyotUFSk8CWwjyXPX7Teui-zJL93tGPl_jUGkDpQfPpy7HF1ELzeWXI_33przajXRaU2rFDTf-OmJAomE_xH8TmXM9yJOYyHqrznyknFTdl9N8vzcjuARIdHfEuygH1u0cndgErkX_l_tfeBZcA?key=f7C-3cR0JMOdp_HXQpeORQ" alt=""/><br/> <img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdQNCiOLjNqAHu0_P-lo_aVpQBjC4f3XN8dtC7EP8iyM_MPVFyC3GroWeyBI0geqrzmniWnw-FPL713703JBfv1cZJthK4_Jx44TNNS0Nmn6Nh39zBejLUowp-cxHpw5biU7FJ7h9L-ml3-46USmG0cO-R2?key=f7C-3cR0JMOdp_HXQpeORQ" alt=""/></li> </ul>]]></content><author><name></name></author><category term="concepts"/><category term="transformer"/><summary type="html"><![CDATA[2018 Most cited paper Largest Model : 340M parameters Bidirectional Encoder Representations from Transformers Improves upon standard transformers ]]></summary></entry><entry><title type="html">Transformers</title><link href="https://artpiazcode.github.io/blog/2023/Transformers/" rel="alternate" type="text/html" title="Transformers"/><published>2023-06-01T00:00:00+00:00</published><updated>2023-06-01T00:00:00+00:00</updated><id>https://artpiazcode.github.io/blog/2023/Transformers</id><content type="html" xml:base="https://artpiazcode.github.io/blog/2023/Transformers/"><![CDATA[<h1 id="transformers">Transformers</h1> <p><a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html</a> </p> <p>Transformers (<a href="https://arxiv.org/pdf/1706.03762.pdf">Vaswani et al, 2017</a>) combine attention and the encoder-decoder structure to improve upon some of the limitations of RNNs in language modelling tasks like translation. Introduces a new concept - self-attention.</p> <h2 id="self-attention-layer">Self attention (layer)</h2> <p>A neural network layer that transforms a sequence of embeddings (for instance, <a href="https://developers.google.com/machine-learning/glossary#token">token</a> embeddings) into another sequence of embeddings. Each embedding in the output sequence is constructed by integrating information from the elements of the input sequence through an <a href="https://developers.google.com/machine-learning/glossary#attention">attention</a> mechanism.</p> <p>The self part of self-attention refers to the sequence attending to itself rather than to some other context. Self-attention is one of the main building blocks for <a href="https://developers.google.com/machine-learning/glossary#Transformer">Transformers</a> and uses dictionary lookup terminology, such as “query”, “key”, and “value”.</p> <p>A self-attention layer starts with a sequence of input representations, one for each word. The input representation for a word can be a simple embedding. For each word in an input sequence, the network scores the relevance of the word to every element in the whole sequence of words. <strong>The relevance scores determine how much the word’s final representation incorporates the representations of other words.</strong></p> <ul> <li> <p>Self attention allows a cell to compare the content of an input to all other inputs in the sequence. </p> </li> <li> <p><strong>Includes the relationship between them into the embedding.</strong></p> </li> <li> <p>For words: self-attention allows representing which other words in a sentence it has strong relationships with.</p> </li> </ul> <p>For example, consider the following sentence:</p> <p>The animal didn’t cross the street because it was too tired.</p> <p>The following illustration (from <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformer: A Novel Neural Network Architecture for Language Understanding</a>) shows a self-attention layer’s attention pattern for the pronoun it, with the darkness of each line indicating how much each word contributes to the representation:</p> <p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcFOSGoyk7hi3ITjd5LiLGN86qc1H2xfyZTvEow219wdpXK6l9lSuk6w7meHCFWZwQf8Blxst4qjx-Ggdtb7qilb5C2Svkf--dSl5w6jF3LDd61gMUZc4gueN0Ckgno3PNzGkLqEX6lylEay-meh3_ZJ7_C?key=f7C-3cR0JMOdp_HXQpeORQ" alt="The following sentence appears twice: 'The animal didn't cross the &#x20; street because it was too tired.' Lines connect the word 'it' in &#x20; one sentence to five tokens ('The', 'animal', 'street', 'it', and &#x20; the period) in the other sentence. The line between 'it' and &#x20; 'animal' is strongest."/></p> <p>The self-attention layer highlights words that are relevant to “it”. In this case, the attention layer has learned to highlight words that it might refer to, assigning the highest weight to animal.</p> <p>For example, deciding on the most likely meaning and appropriate representation of the word “bank” in the sentence “I arrived at the bank after crossing the…” requires knowing if the sentence ends in “… road.” or “… river.”</p> <p>To compute the next representation for a given word - “bank” for example - <strong>the Transformer compares it to every other word in the sentence.</strong> The <strong>result of these comparisons is an attention score for every other word in the sentence.</strong> These attention scores determine how much each of the other words should contribute to the next representation of “bank”. In the example, the disambiguating “river” could receive a high attention score when computing a new representation for “bank”. <strong>The attention scores are then used as weights for a weighted average of all words’ representations which is fed into a fully-connected network to generate a new representation for “bank”, reflecting that the sentence is talking about a river bank.</strong></p> <p><strong>For a sequence of n</strong> <a href="https://developers.google.com/machine-learning/glossary#token"><strong>tokens</strong></a><strong>, self-attention transforms a sequence of embeddings n separate times, once at each position in the sequence.</strong></p> <p><strong>Attention vs self-attention:</strong></p> <ul> <li> <p>Attention allows output to focus attention on input while producing output.</p> </li> <li> <p>Self-attention allows inputs to interact with each other i.e. calculate attention of all other inputs wrt one input.</p> </li> </ul> <h2 id="multi-head-self-attention"><strong>Multi-head self-attention</strong>.</h2> <p>An extension of <a href="https://developers.google.com/machine-learning/glossary#self-attention">self-attention</a> that applies the self-attention mechanism multiple times for each position in the input sequence.</p> <p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXddbpGsumHN_8HzHQWzr7aGJ2-_pDrAwnWplF2UprTtkShaYU73l6THa6NnIJ5hDRaPPZGjU2-i3P0ivylunKUEqexbWnEm_c5JRrpl21jPEUMpQPNPt12Wqb3XkeMZLZtSLnPyT-Fxji4v-yJ90w0E54Kh?key=f7C-3cR0JMOdp_HXQpeORQ" alt=""/></p> <p>The structure of transformers looks like:</p> <p>Transformers (e.g. GPT-4, LaMDA, Wu-Dao) are neural networks that learn context and meaning by closely tracking relationships in sequential data. LLMs are <a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">transformer-based models</a>. </p> <p><strong>Transformer architecture</strong></p> <p>\</p> <p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXd3LRh8UajU1xRAIICPPBouHT5B-UXdRLX6C-qqXAHXOM7-eVSu-kGl-QhPQGoqiojaP3wciYXgcOAiM-AxX96iWUgihP6PWQO_rBLempOuhRf-d07EoYhIoJFL1_VcLk-v88CJVcImoLz3DZOhw9CV-TlL?key=f7C-3cR0JMOdp_HXQpeORQ" alt=""/></p> <p>\</p> <p>Different types of architectures are relevant for different types of tasks: </p> <ul> <li> <p><strong>Encoder-only</strong>: Encoder only models use only the encoder of the transformer. It maps input text into an intermediate representation, aka embedding, which could serve as the input for downstream applications, like classifications. e.g. BERT. The one-model initiative in AnA is an example of an Encoder-only model.</p> </li> <li> <p><strong>Encoder-decoder</strong>: These are essentially seq-to-seq models. It adds a decoder which maps intermediate representations into text output, which are used for generating text with a given input, such as summarization, or translation. Attention allows the decoder network to focus on relevant parts of the input when producing an output i.e. enhances some parts of the input data while diminishing the others. The idea is that there might be relevant information in every word in a sentence. So in order for the decoding to be precise, it needs to take into account all words of the input, using attention. Adds an extra input to each decoding step that comes from the encoding steps. e.g. MUM</p> </li> <li> <p><strong>Decoder-only:</strong> Decoder models use only the decoder of a Transformer model. At each stage, for a given word the attention layers can only access the words positioned before it in the sentence. It is fed the original text, produces some output and this output is used as an input back into itself and these models are often called <strong>auto-regressive</strong> models. These models are well suited for tasks involving text generation. E.g. PaLM, ChatGPT</p> </li> </ul> <p>The structure of transformers looks like:</p> <p><img src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXe7NncVvfQIOJzJ_1xBbmiqKGYCxrf22x-677KIEFwNEq1DmrtcdprUSNdI7_DqwWm2mBgsfWzykuMKWgyIXclEs8HdWUO5JL-CQtGI2cWU5i_weklv3gF9yyobVYUHJtRS6xWLCIsuh2cFRyqUHEv2Y_52?key=f7C-3cR0JMOdp_HXQpeORQ" alt=""/></p> <ul> <li>Attention architecture is mostly unchanged today, but some details have changed (positional embeddings, learning rates, pre-norm attention)</li> </ul>]]></content><author><name></name></author><category term="concepts"/><category term="transformer"/><summary type="html"><![CDATA[Transformers]]></summary></entry></feed>